{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed2782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "def load_encodings_from_folder(folder_path):\n",
    "    encodings = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(\".txt\"):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                encodings[file_name[:-4]] = [float(line.strip()) for line in lines]\n",
    "    return encodings\n",
    "\n",
    "def find_nearest_match(unknown_encoding, known_encodings):\n",
    "    best_match_name = None\n",
    "    best_distance = float('inf')\n",
    "\n",
    "    for name, known_encoding in known_encodings.items():\n",
    "        distance = face_recognition.face_distance([known_encoding], unknown_encoding)[0]\n",
    "\n",
    "        if distance < best_distance:\n",
    "            best_distance = distance\n",
    "            best_match_name = name\n",
    "\n",
    "    return best_match_name, best_distance\n",
    "\n",
    "def recognize_faces_in_video(video_capture, known_encodings_folder, output_video_path):\n",
    "    known_encodings = load_encodings_from_folder(known_encodings_folder)\n",
    "\n",
    "    # Get video properties\n",
    "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    # Define codec and create VideoWriter object with 640x480 resolution\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (640, 480))\n",
    "\n",
    "    # Skip every 2 frames for faster processing\n",
    "    frame_skip = 2\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        # Read the next frame from the video\n",
    "        _, frame = video_capture.read()\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        # Skip frames if needed\n",
    "        if frame_count % frame_skip != 0:\n",
    "            continue\n",
    "\n",
    "        # Resize the frame to 640x480\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "        # Convert the frame from BGR to RGB (as face_recognition uses RGB)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Find all face locations and face encodings in the current frame\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        # Process each face in the frame\n",
    "        for face_location, face_encoding in zip(face_locations, face_encodings):\n",
    "            # Find the nearest match for each face\n",
    "            best_match_name, best_distance = find_nearest_match(face_encoding, known_encodings)\n",
    "\n",
    "            # Draw a rectangle around the face\n",
    "            top, right, bottom, left = face_location\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            # Put the name on the rectangle\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, best_match_name, (left + 6, bottom - 6), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        out.write(frame)\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release resources\n",
    "    video_capture.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage\n",
    "video_path = 'path/to/your/video.mp4'\n",
    "known_encodings_folder = 'path/to/known/encodings'\n",
    "output_video_path = 'path/to/output/video.avi'\n",
    "\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "recognize_faces_in_video(video_capture, known_encodings_folder, output_video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
